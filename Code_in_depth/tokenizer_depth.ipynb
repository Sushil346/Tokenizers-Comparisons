{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "provenance": [],
      "gpuType": "T4"
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    },
    "accelerator": "GPU"
  },
  "cells": [
    {
      "cell_type": "code",
      "source": [
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-cased\")\n",
        "\n",
        "encoded_input = tokenizer(\"Hello, I'm a Damodar Bagale!\")\n",
        "print(encoded_input)"
      ],
      "metadata": {
        "id": "3kBvqlC_IA-r",
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "outputId": "b832d302-7df2-4668-e282-72e6b7572f44"
      },
      "execution_count": 36,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [101, 8667, 117, 146, 112, 182, 170, 8732, 16848, 1197, 18757, 6997, 1162, 106, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0, 0], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "tokenizer.decode(encoded_input[\"input_ids\"])"
      ],
      "metadata": {
        "id": "az2a2d3SIA75",
        "colab": {
          "base_uri": "https://localhost:8080/",
          "height": 35
        },
        "outputId": "ebbdde5d-55ff-49d0-a959-144c1d3bdcdb"
      },
      "execution_count": 37,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "\"[CLS] Hello, I ' m a Damodar Bagale! [SEP]\""
            ],
            "application/vnd.google.colaboratory.intrinsic+json": {
              "type": "string"
            }
          },
          "metadata": {},
          "execution_count": 37
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "encoded_input = tokenizer(\"How are you?\", \"I'm fine, thank you!\")\n",
        "print(encoded_input)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "1zNyzhIhLA2E",
        "outputId": "15a806ed-37fa-47f1-8eaf-ab7ee69f2f2f"
      },
      "execution_count": 38,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "{'input_ids': [101, 1731, 1132, 1128, 136, 102, 146, 112, 182, 2503, 117, 6243, 1128, 106, 102], 'token_type_ids': [0, 0, 0, 0, 0, 0, 1, 1, 1, 1, 1, 1, 1, 1, 1], 'attention_mask': [1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1, 1]}\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# // lets' do the same but see for different models..\n",
        "# how they tokenizes\n",
        "\n",
        "from transformers import AutoTokenizer\n",
        "\n",
        "tokenizers = {\n",
        "\n",
        "        \"GPT-2 (BPE)\": \"gpt2\",\n",
        "        \"Bert (WordPiece)\": \"bert-base-cased\",\n",
        "        \"T5 (BPE)\": \"t5-small\",\n",
        "\n",
        "}\n",
        "\n",
        "test_texts = {\n",
        "\n",
        "          \"Shree Ganeshaya Namah !!\",\n",
        "          \"Wau, Tokenization is really interssting !\",\n",
        "          \"I love my Country, Nepal\"\n",
        "\n",
        "}\n",
        "\n",
        "for name, model in tokenizers.items():\n",
        "  tokenizer = AutoTokenizer.from_pretrained(model)\n",
        "  print(f\" \\n{'-'*50}\")\n",
        "  print(f\"  {name} -- vocab: {tokenizer.vocab_size:,}\")\n",
        "  print('='*60)\n",
        "\n",
        "  for text in test_texts:\n",
        "    tokens = tokenizer.tokenize(text)\n",
        "    ids = tokenizer.encode(text)\n",
        "    decoded = tokenizer.decode(ids)\n",
        "\n",
        "    print(f\"\\n Text: {text}\")\n",
        "    print(f\"Tokens: {tokens}\")\n",
        "    print(f\"count: {len(tokens)} tokens\")\n",
        "    print(f\" Decoded: {decoded}\")\n",
        "\n",
        "  print()"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "bSgyojmxhaPv",
        "outputId": "33de74e2-aa37-45bd-f7b6-bd5aa030f478"
      },
      "execution_count": 39,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            " \n",
            "--------------------------------------------------\n",
            "  GPT-2 (BPE) -- vocab: 50,257\n",
            "============================================================\n",
            "\n",
            " Text: Wau, Tokenization is really interssting !\n",
            "Tokens: ['W', 'au', ',', 'ĠToken', 'ization', 'Ġis', 'Ġreally', 'Ġinter', 's', 'st', 'ing', 'Ġ!']\n",
            "count: 12 tokens\n",
            " Decoded: Wau, Tokenization is really interssting !\n",
            "\n",
            " Text: I love my Country, Nepal\n",
            "Tokens: ['I', 'Ġlove', 'Ġmy', 'ĠCountry', ',', 'ĠNepal']\n",
            "count: 6 tokens\n",
            " Decoded: I love my Country, Nepal\n",
            "\n",
            " Text: Shree Ganeshaya Namah !!\n",
            "Tokens: ['Sh', 'ree', 'ĠGan', 'esh', 'aya', 'ĠNam', 'ah', 'Ġ!!']\n",
            "count: 8 tokens\n",
            " Decoded: Shree Ganeshaya Namah !!\n",
            "\n",
            " \n",
            "--------------------------------------------------\n",
            "  Bert (WordPiece) -- vocab: 28,996\n",
            "============================================================\n",
            "\n",
            " Text: Wau, Tokenization is really interssting !\n",
            "Tokens: ['W', '##au', ',', 'To', '##ken', '##ization', 'is', 'really', 'inter', '##ss', '##ting', '!']\n",
            "count: 12 tokens\n",
            " Decoded: [CLS] Wau, Tokenization is really interssting! [SEP]\n",
            "\n",
            " Text: I love my Country, Nepal\n",
            "Tokens: ['I', 'love', 'my', 'Country', ',', 'Nepal']\n",
            "count: 6 tokens\n",
            " Decoded: [CLS] I love my Country, Nepal [SEP]\n",
            "\n",
            " Text: Shree Ganeshaya Namah !!\n",
            "Tokens: ['S', '##hr', '##ee', 'G', '##ane', '##sha', '##ya', 'Nam', '##ah', '!', '!']\n",
            "count: 11 tokens\n",
            " Decoded: [CLS] Shree Ganeshaya Namah!! [SEP]\n",
            "\n",
            " \n",
            "--------------------------------------------------\n",
            "  T5 (BPE) -- vocab: 32,100\n",
            "============================================================\n",
            "\n",
            " Text: Wau, Tokenization is really interssting !\n",
            "Tokens: ['▁Wa', 'u', ',', '▁To', 'ken', 'ization', '▁is', '▁really', '▁inter', 's', 'sting', '▁', '!']\n",
            "count: 13 tokens\n",
            " Decoded: Wau, Tokenization is really interssting!</s>\n",
            "\n",
            " Text: I love my Country, Nepal\n",
            "Tokens: ['▁I', '▁love', '▁my', '▁Country', ',', '▁Nepal']\n",
            "count: 6 tokens\n",
            " Decoded: I love my Country, Nepal</s>\n",
            "\n",
            " Text: Shree Ganeshaya Namah !!\n",
            "Tokens: ['▁Sh', 're', 'e', '▁Ga', 'nes', 'hay', 'a', '▁Nam', 'a', 'h', '▁', '!!']\n",
            "count: 12 tokens\n",
            " Decoded: Shree Ganeshaya Namah!!</s>\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# For Padding & Truncation\n",
        "\n",
        "tokenizer = AutoTokenizer.from_pretrained(\"bert-base-uncased\")\n",
        "sequences = [\n",
        "\n",
        "        \"Hello, Its me ...\",\n",
        "        \"I am a student from Nepal, who love his country\",\n",
        "        \"Actually I am enjoying understanding it deeply after vibing, lol\",\n",
        "\n",
        "]\n",
        "\n",
        "print('\\n' + '-' * 60)\n",
        "print(\"Padding & Truncation\")\n",
        "print('-' * 60)\n",
        "\n",
        "# No Padding\n",
        "result = tokenizer(sequences)\n",
        "print(\"\\nNo padding --lengths: \", [len(x) for x in result['input_ids']])\n",
        "\n",
        "# // with padding\n",
        "result = tokenizer(sequences, padding=True)\n",
        "print(\"With padding -- lengths : \" , [len(x) for x in result['input_ids']])\n",
        "\n",
        "result = tokenizer(sequences, padding=True, truncation=True, max_length=14)\n",
        "print(\"With padding & truncation -- lengths : \" , [len(x) for x in result['input_ids']])"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "WkljYO3Ilxxe",
        "outputId": "1705b860-a5b3-4c46-ef3b-bd8356585097"
      },
      "execution_count": 40,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "\n",
            "------------------------------------------------------------\n",
            "Padding & Truncation\n",
            "------------------------------------------------------------\n",
            "\n",
            "No padding --lengths:  [9, 13, 15]\n",
            "With padding -- lengths :  [15, 15, 15]\n",
            "With padding & truncation -- lengths :  [14, 14, 14]\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "# //Checking different models architecture using config files..\n",
        "\n",
        "rom transformers import AutoConfig, AutoModel, AutoModelForSequenceClassification\n",
        "\n",
        "# Understanding model architectures\n",
        "models = {\n",
        "    \"BERT base\": \"bert-base-uncased\",\n",
        "    \"DistilBERT\": \"distilbert-base-uncased\",\n",
        "    \"GPT-2\": \"gpt2\",\n",
        "}\n",
        "\n",
        "print(\"MODEL COMPARISON\")\n",
        "print(\"=\"*80)\n",
        "\n",
        "for name, checkpoint in models.items():\n",
        "    config = AutoConfig.from_pretrained(checkpoint)\n",
        "    model = AutoModel.from_pretrained(checkpoint)\n",
        "\n",
        "    print(config)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "NxnaWxySjKQm",
        "outputId": "7050087e-3229-4eda-d84a-3b391a22000c"
      },
      "execution_count": 41,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "MODEL COMPARISON\n",
            "================================================================================\n",
            "BertConfig {\n",
            "  \"architectures\": [\n",
            "    \"BertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_probs_dropout_prob\": 0.1,\n",
            "  \"classifier_dropout\": null,\n",
            "  \"gradient_checkpointing\": false,\n",
            "  \"hidden_act\": \"gelu\",\n",
            "  \"hidden_dropout_prob\": 0.1,\n",
            "  \"hidden_size\": 768,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"intermediate_size\": 3072,\n",
            "  \"layer_norm_eps\": 1e-12,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"bert\",\n",
            "  \"num_attention_heads\": 12,\n",
            "  \"num_hidden_layers\": 12,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"position_embedding_type\": \"absolute\",\n",
            "  \"transformers_version\": \"4.57.3\",\n",
            "  \"type_vocab_size\": 2,\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "DistilBertConfig {\n",
            "  \"activation\": \"gelu\",\n",
            "  \"architectures\": [\n",
            "    \"DistilBertForMaskedLM\"\n",
            "  ],\n",
            "  \"attention_dropout\": 0.1,\n",
            "  \"dim\": 768,\n",
            "  \"dropout\": 0.1,\n",
            "  \"hidden_dim\": 3072,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"max_position_embeddings\": 512,\n",
            "  \"model_type\": \"distilbert\",\n",
            "  \"n_heads\": 12,\n",
            "  \"n_layers\": 6,\n",
            "  \"pad_token_id\": 0,\n",
            "  \"qa_dropout\": 0.1,\n",
            "  \"seq_classif_dropout\": 0.2,\n",
            "  \"sinusoidal_pos_embds\": false,\n",
            "  \"tie_weights_\": true,\n",
            "  \"transformers_version\": \"4.57.3\",\n",
            "  \"vocab_size\": 30522\n",
            "}\n",
            "\n",
            "GPT2Config {\n",
            "  \"activation_function\": \"gelu_new\",\n",
            "  \"architectures\": [\n",
            "    \"GPT2LMHeadModel\"\n",
            "  ],\n",
            "  \"attn_pdrop\": 0.1,\n",
            "  \"bos_token_id\": 50256,\n",
            "  \"embd_pdrop\": 0.1,\n",
            "  \"eos_token_id\": 50256,\n",
            "  \"initializer_range\": 0.02,\n",
            "  \"layer_norm_epsilon\": 1e-05,\n",
            "  \"model_type\": \"gpt2\",\n",
            "  \"n_ctx\": 1024,\n",
            "  \"n_embd\": 768,\n",
            "  \"n_head\": 12,\n",
            "  \"n_inner\": null,\n",
            "  \"n_layer\": 12,\n",
            "  \"n_positions\": 1024,\n",
            "  \"reorder_and_upcast_attn\": false,\n",
            "  \"resid_pdrop\": 0.1,\n",
            "  \"scale_attn_by_inverse_layer_idx\": false,\n",
            "  \"scale_attn_weights\": true,\n",
            "  \"summary_activation\": null,\n",
            "  \"summary_first_dropout\": 0.1,\n",
            "  \"summary_proj_to_labels\": true,\n",
            "  \"summary_type\": \"cls_index\",\n",
            "  \"summary_use_proj\": true,\n",
            "  \"task_specific_params\": {\n",
            "    \"text-generation\": {\n",
            "      \"do_sample\": true,\n",
            "      \"max_length\": 50\n",
            "    }\n",
            "  },\n",
            "  \"transformers_version\": \"4.57.3\",\n",
            "  \"use_cache\": true,\n",
            "  \"vocab_size\": 50257\n",
            "}\n",
            "\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [],
      "metadata": {
        "id": "MTmtk4Xvr4ds"
      },
      "execution_count": 42,
      "outputs": []
    }
  ]
}